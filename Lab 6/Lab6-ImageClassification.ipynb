{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6 - Intro to Image Classification with Convolutional Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background - Image Classification\n",
    "\n",
    "For this project you will be introduced to the basics of Convolutional Neural Networks (CNNs) and the PyTorch framework.  Deep learning with CNNs can be very computationally expensive and runs fastest with GPU support.  If you do not have access to GPUs on your local machine, you can use some from Google using their [colab tool](https://colab.research.google.com).  Colab runs exactly like jupyter notebooks and you can directly upload your .ipynb file. If you have a Mac machine that has a M1 or M2 processor, you can also use MPS acceleration for a slight speed up.\n",
    "\n",
    "Image classification is the task of taking an image and labeling it as a category.  CNNs have been a leading method for image classification since it dominated the [ImageNet competition in 2012](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf).\n",
    "\n",
    "The instructions for the lab are contained in this Jupyter notebook. **You may choose to complete the lab in this notebook, or you may choose to complete the lab in standard Python using the .py template file.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A: Dataset\n",
    "\n",
    "You will be performing classification on the [Stanford Cars Dataset](https://www.kaggle.com/datasets/jessicali9530/stanford-cars-dataset), which consists of 16,185 images of 196 classes of cars.  The dataset is split 50-50 into a training set and testing set.  You can download the images and the needed annotation files from this [Google Drive folder](https://drive.google.com/drive/folders/1GLHQAt3KNN_3eIETkinzlY5q9HG44Blx?usp=sharing).  Each set is around 1 GB of data so please **<span style=\"color:red\">DO NOT</span>** include the files when you upload your notebook--**just turn in the .ipynb or .py file**.  Assume the notebooks will be run with the images in folders labeled `cars_train` and `cars_test` like so:\n",
    "\n",
    "```\n",
    ".\n",
    "+--proj6-image-classification.ipynb\n",
    "+--cars_train\n",
    "|  +--00001.jpg\n",
    "|  +--00002.jpg\n",
    "|  +--...\n",
    "+--cars_test\n",
    "|  +--00001.jpg\n",
    "|  +--00002.jpg\n",
    "|  +--...\n",
    "+--test_annos.json\n",
    "+--train_annos.json\n",
    "```\n",
    "\n",
    "The first step in any neural network method is to make sure you can read in the data.  Since there will be a lot of images for this project, not all of them will fit into memory.  This is a common problem in CNNs and PyTorch has provided a pattern so as to only have the images you need in memory at any given time.  They provide a class called `DataLoader` that acts as an iterable object.  To use `DataLoader`, you will need to implement a subclass of PyTorch's `Dataset` class.  To do you so will need to create a class that inherits from `Dataset` and implements the methods `__getitem__` and `__len__`. A template is given below and PyTorch provides a [tutorial here](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html). You can also reference the Custom Image Loader found in [this tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files).\n",
    "\n",
    "We provide you with two files `test_annos.json` and `train_annos.json`.  These files contain a dictionary mapping image name to the class label the image belongs to.  You can use these files in you Dataset class in order to provide the ground truth labels.  \n",
    "\n",
    "To complete part A, implement a dataset class for the cars dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK 1: Implement Data Loader ###\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, labels_fn, image_dir):\n",
    "        super(MyDataset, self).__init__()\n",
    "        # TODO: implement what happens when someone calls: dataset = MyDataset()\n",
    "        # Pull in relevant file information, images lists, etc.\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # TODO: implement what happens when someone calls dataset[idx]\n",
    "        # Return an image and it's associated label at location idx \n",
    "    \n",
    "    def __len__(self):\n",
    "        # TODO: implement what happens when someone calls len(dataset)\n",
    "        # Determine the number of images in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test your dataset loader by running the following code (You don't have to let it run through the whole dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = MyDataset(\"train_annos.json\", \"cars_train\")\n",
    "loader = DataLoader(training_dataset,batch_size=1)\n",
    "for im, label in loader:\n",
    "      print(im.shape,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional Notes and Tips**:\n",
    "\n",
    "- Both the images and the labels are 1-indexed. You can load the images however you choose, but the labels must be 0-indexed to work with Pytorch's loss functions. Make sure to account for this in your Dataset class.\n",
    "\n",
    "- Make sure the images and labels that are returned are both PyTorch tensors. Specifically, the images should be returned as Tensors that are rearranged to be shape [channels, rows, cols] and should be values between 0 and 1. To guarantee this, I recommend using `read_image` from `torchvision.io` and dividing by 255.\n",
    "\n",
    "- Some of the images in the dataset are grayscale while most are RGB. To prevent issues later, make sure to load all images as RGB. If you use `read_image`, you can use `ImageReadMode.RGB` to guarantee that all images have 3 channels.\n",
    "\n",
    "- Python has a [json library](https://docs.python.org/3/library/json.html) that you can use to turn json files in to Python dictionaries. You can look up some simple tutorials online."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B: Neural Network Architecture\n",
    "\n",
    "The main backbone for deep learning is the actual neural network architecture.  For image classification, this will consist of some combination of `Conv2d` layers with activations--usually `ReLU`--with intermitted downsampling--usually done using `MaxPool2d`--followed by a few Linear layers.  The input to the network should be an image with shape `(batch_size, channels, image_height, image_width)`(e.g. an single image with dimensions 224x224 would be `(1, 3, 224, 224)`) and output a vector of shape `(num_classes,)` where the largest value's index in the output vector indicates the class label.  \n",
    "\n",
    "While we built our own network in the mini-lab, for this lab, we will use one of Pytorch's pretrained networks. This has the benefit of already having learned features from training on an ImageNet classification problem. To pull in this pretrained network, we use the following line of code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "print(list(model.__dict__[\"_modules\"].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ResNet18 is a common baseline network that uses convolution layers, batch normalization, layers of residual blocks, and a fully connected layer at the end. The different layers are listed above. However, because the pretrained network was trained on ImageNet, the last layer is designed to predict 1000 classes, not 196 like in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to use the same architecture as the ResNet, but replace the last fully connected layer with a new fully connected layer that goes from 512 input features to 196 output features.\n",
    "\n",
    "PyTorch provides a nice framework for making a neural network architecture.  A network is typically made as a class that inherits from PyTorch's `Module` class and implements the `forward` method.  A network might take the form of the template provided below. PyTorch also provides a simple Neural Network [tutorial here](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html), the Training a Classifier tutorial is especially helpful.\n",
    "\n",
    "To complete part B, make your own neural network by taking all the pretrained layers from ResNet18, but then defining your own last fully connected layer. Then write the appropriate forward pass function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TASK 2: Design Neural Network ###\n",
    "\n",
    "import torch.nn as nn \n",
    "\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        ref_model = torchvision.models.resnet18(pretrained=True)\n",
    "        self.conv1 = ref_model.conv1\n",
    "        self.bn1 = ref_model.bn1\n",
    "        self.relu = ref_model.relu\n",
    "        # TODO: Continue network setup here\n",
    "        # TODO: Replace fc layer with your own linear layer that outputs 196 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        # TODO: Continue feeding output through all layers of the network\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative approach to defining the ResNet architecture is to modify the fully connected layer inplace. You are allowed to do this instead for this lab.\n",
    "\n",
    "You can test that your network is defined correctly by running the following code. The expected output shape is (1,196)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model = MyNetwork()\n",
    "test_im = torch.zeros((1,3,256,256))\n",
    "output = model(test_im)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C: Training\n",
    "\n",
    "Now that you can access your data and you have a network architecture setup, it's time to put things together and start training.  Training requires two major components: 1) the loss function and 2) the optimizer.  The loss function is a comparison between your results and the ground truth data.  The optimizer is what takes the results of the loss function and backpropagates the error to the network weights in an attempt to decrease the loss.  The most common loss function used for classification is [Cross Entropy](https://pytorch.org/docs/stable/nn.html#crossentropyloss) while the most commonly used optimizer function is [Adam](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam).  \n",
    "\n",
    "It is common to run through the training data multiple times. Each run through the training data is called an **epoch**. You will only be required to do one epoch, but you may increase the number of epochs to increase the accuracy of the network. \n",
    "\n",
    "A basic training loop might take the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 3: Modify the training loop ###\n",
    "import torch\n",
    "\n",
    "training_dataset = MyDataset(\"train_annos.json\",\"cars_train\")\n",
    "train_loader = DataLoader(training_dataset,batch_size=1,shuffle=True)\n",
    "\n",
    "model = MyNetwork()\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 1\n",
    "model.train() # Put network into training mode, where neural network weights can change\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for images,labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outs = model(images)\n",
    "        loss = loss_func(outs, labels)  # loss_func would be an instance of a torch.nn.CrossEntropyLoss class\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you defined your network and dataset class correctly, you will find that this training loop runs. However, you will find that it runs incredibly slowly. Additionally, we have no way of verifying if the network is learning/converging over time. \n",
    "\n",
    "To complete this part of the lab, modify the code in the following ways:\n",
    "\n",
    "- Impement a counter that prints out the loss after every 20 passes. Use `loss.item()` to get the value without the tensor info. If things are working, the average loss should gradually decrease over time.\n",
    "- Save that loss to an array so you can plot the loss after training is completed.\n",
    "- Increase the batch size of your training network. To do so, you will need to guarantee that all images in a batch are the same spatial resolution or it will not run. Thus, you will need to add random crop data augmentation inside your dataset class, but make sure the crop is not too small, otherwise you might miss parts of the car.\n",
    "\n",
    "Additionally, you may modify your code to include GPU acceleration using .cuda calls in the appropriate places. If you have an M1 or M2 processor Mac, you can modify your code to have MPS acceleration.\n",
    "\n",
    "After making the modifications, run the training loop for at least one epoch. Then, plot your loss over time in following code cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualization of the loss ###\n",
    "\n",
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional Notes and Tips**:\n",
    "\n",
    "- Mac computers sometimes create .DS_STORE files inside of directories. If your training or testing loop breaks at a random time, it may be trying to load a hidden .DS_STORE file that it thinks is an image. Since they are hidden in the the Finder window, you will need to use the terminal to navigate to the data folder and use command `rm .DS_STORE`.\n",
    "\n",
    "- If you want a good sense of how long your code is going to take to run, use the `tqdm` class to time the FOR loop.\n",
    "\n",
    "-  ResNet was trained with images that are normalized according to the ImageNet color averages. This means you may want to include an appropriate normalization in your Dataset class if you did not already. This can easily be done with Pytorch's transform objects.\n",
    "\n",
    "```Python\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "```\n",
    "\n",
    "- This step could take several hours, so it is recommended that you save your model to a file every couple hundered steps to avoid losing work. You can find additional details on the [PyTorch website](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n",
    "\n",
    "- It is recommended that you save your loss plot as an image file in case you need to restart the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part D: Testing\n",
    "\n",
    "One of the goals of deep learning is to make a model that generalizes to data it has never seen (e.g. new images of cars).  For this part, you will test your generalizability by running the model on a dataset it has not yet seen during training.  To do so, you will need to make sure you are not calculating any of the gradients by using `torch.no_grad` in a with statement. You will aslo need to put the network into evaluation mode using `model.eval()`. For reference, to put the network back into training mode, call `model.train()`.\n",
    "\n",
    "You will compare your predictions with the ground truth value for value.  The output of your network, however, will be a vector of length 196 (the number of possible classes for the cars dataset) with the **largest** value representing the guessed class.  You'll need to extract the guessed class number and compare it with the ground truth number for all images in the test dataset. Then you will calculate the overall accuracy of your predictor. While high test accuracy is not the only goal in this lab, most students are able to get above **50%** in their testing accuracy. If you are unable to reach this level of accuracy, it may indicate an error in your code.\n",
    "\n",
    "Additionally, you will generate a confusion matrix of the 196 categories. A confusion matrix shows how often a specific category is guessed as each other category. For example, the 11th row and 34th column in the matrix should tell you how many times category 11 images were guessed to be category 34 images. Thus, a perfect predictor on the test set would have nonzero values only along the diagnol. Large values that are not along the diagnol can help indicate categories that were hard to distinguish from each other (i.e. cars that look similar). A good blog post on the topic can be found [here](https://www.mariakhalusova.com/posts/2019-04-17-ml-model-evaluation-metrics-p2/).\n",
    "\n",
    "To complete this part of the lab:\n",
    "- Go through the testing dataset and make a list of all model predictions and a list of groundtruth labels.\n",
    "- Using the two lists, calculate the total accuracy of the model and print this to the screen.\n",
    "- Using the two lists, calculate and plot the confusion matrix for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Task 4: Test the Network ###\n",
    "\n",
    "test_dataset = MyDataset(\"test_annos.json\",\"cars_test\")\n",
    "test_loader = DataLoader(test_dataset,batch_size=1)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # enter prediction and ground truth extraction code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy calculation code here\n",
    "\n",
    "\n",
    "# Confusion matrix visual here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Additional Notes and Tips**:\n",
    "- You can write your test code before you fully train your model. For example, if your model takes a long time to train, train it for a few steps, stop it early, use the poorly trained model to debug your test code, then go back and train it fully later.\n",
    "\n",
    "- For the confusion matrix calculations, it should be pretty easy to implement using a for loop and a np.zeros(196,196) buffer, but you are welcome to use sklearn's confusion matrix package if you prefer.\n",
    "\n",
    "- For plotting the confusion matrix, you can simply use plt.imshow with interpolation off. If you want a nicer looking plot, you can the seaborn package with the heatmap function as described [here](https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea). \n",
    "\n",
    "- It is recommended that you save your accuracy and your confusion matrix plot to file in case you need to restart the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning in your assignment\n",
    "\n",
    "To turn in this assignment, turn in this notebook with the following pieces:\n",
    "- Code for the dataset loader, the neural network, the training loop, and testing.\n",
    "- A visual of the loss value plotted over time during the training.\n",
    "- A print out of the accuracy on the test set.\n",
    "- A visual of the confusion matrix on the test set.\n",
    "\n",
    "**DO NOT TURN IN:**\n",
    "- The dataset files\n",
    "- The saved neural network weights\n",
    "\n",
    "These files are too large to upload to Canvas, and students who fail to follow these instructions will be docked points. Also, the graders will not rerun your training loop from scratch, so make sure all the visuals are visible on your notebook when you submit.\n",
    "\n",
    "If you chose to run your code from the .py file, please submit your code as one file and screenshots of the loss value plot, accuracy, and confusion matrix separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Credit Competition (5 pts)\n",
    "\n",
    "An additional 5 pts of extra credit will be given to the individual with the highest test accuracy. You can try to improve the accuracy of your network using strategies such as data augmentation, learning rate schedulers, or different optimizers and batch sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
